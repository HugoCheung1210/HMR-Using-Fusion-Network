{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2BToKQqcB6U0"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mediapipe"
      ],
      "metadata": {
        "id": "W-YIDhotTvbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import librosa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn \n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import mediapipe as mp\n",
        "from torchvision import transforms\n",
        "import shutil\n",
        "from PIL import Image\n",
        "from google.colab.patches import cv2_imshow\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets,transforms\n",
        "from torch.optim import lr_scheduler\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import time\n",
        "import copy\n",
        "import os\n",
        "from sklearn.metrics import accuracy_score,f1_score, confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "\n"
      ],
      "metadata": {
        "id": "v9mGzRXQGq27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/MyDrive/4010/Image/A\"\n",
        "o_path = \"/content/drive/MyDrive/4010/skeleton_image/A\"\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_pose = mp.solutions.pose\n",
        "for i in range(2,9):\n",
        "  data_path = path+str(i)+\"/\"\n",
        "  output_path = o_path+str(i)+\"/\"\n",
        "  print(data_path)\n",
        "  for filename in os.listdir(data_path):\n",
        "    image_path = data_path+filename\n",
        "    text = \"\"\n",
        "    with mp_pose.Pose(\n",
        "      # these two values are default setting already work pretty well\n",
        "      # higher confidence = higher accuracy of the detection model\n",
        "        model_complexity = 2,\n",
        "        min_detection_confidence=0.4,  \n",
        "        min_tracking_confidence=0.5) as pose:\n",
        "\n",
        "        image = cv2.imread(image_path, -1)\n",
        "\n",
        "        image = cv2.cvtColor(cv2.flip(image, 1), cv2.COLOR_BGR2RGB)    \n",
        "        \n",
        "        image.flags.writeable = False\n",
        "\n",
        "        # make detection\n",
        "        results = pose.process(image)\n",
        "\n",
        "\n",
        "        # Draw the pose annotation on the image.\n",
        "        image.flags.writeable = True\n",
        "      \n",
        "        \n",
        "        # recolor the image to BGR format\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "        img = cv2.imread('./black.jpg')\n",
        "        annotated_image = img.copy()\n",
        "        mp_drawing.draw_landmarks(\n",
        "        img, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
        "            mp_drawing.DrawingSpec(color=(0,255,255), thickness=5, circle_radius=2),\n",
        "            mp_drawing.DrawingSpec(color=(0,255,255), thickness=5, circle_radius=4))\n",
        "        \n",
        "        # cv2_imshow(img)\n",
        "        \n",
        "        p = transforms.Compose([transforms.Resize((100,100))])\n",
        "        hi = Image.fromarray(img)\n",
        "        img = p(hi)\n",
        "        oput = np.array(img)\n",
        "\n",
        "        cv2.imwrite(os.path.join(output_path)+ filename[:-4]+'.jpg', oput)\n"
      ],
      "metadata": {
        "id": "TDqHu2zPRqhQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Framing images"
      ],
      "metadata": {
        "id": "yEDvOvqvxy9k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def framing(path):\n",
        "    # Load 10 images\n",
        "    images = []\n",
        "    for filename in os.listdir(path):\n",
        "      img_path = path+filename\n",
        "      img = cv2.imread(img_path)\n",
        "      images.append(img)\n",
        "\n",
        "      if len(images)==10:\n",
        "      # Concatenate images horizontally\n",
        "        result = np.hstack(images)\n",
        "        # Display result\n",
        "        cv2_imshow(result)\n",
        "        break\n",
        "      \n",
        "framing(\"/content/drive/MyDrive/4010/skeleton_image/A2/\")"
      ],
      "metadata": {
        "id": "Q8rct2GtxyOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Coordinate vector extracting"
      ],
      "metadata": {
        "id": "kac6hk3FV8uk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = {\"labels\":[], \"feature\":[]}\n",
        "path = \"/content/drive/MyDrive/4010/Image/\"\n",
        "mp_pose = mp.solutions.pose\n",
        "\n",
        "for label_index, filename in enumerate(os.listdir(path)):\n",
        "  class_dir = path+\"/\"+filename\n",
        "  ct = 0\n",
        "  for file in os.listdir(class_dir):\n",
        "    file_path = class_dir+\"/\"+file\n",
        "    text=\"\"\n",
        "    with mp_pose.Pose(\n",
        "    # these two values are default setting already work pretty well\n",
        "    # higher confidence = higher accuracy of the detection model\n",
        "      model_complexity = 2,\n",
        "      min_detection_confidence=0.5,  \n",
        "      min_tracking_confidence=0.5) as pose:\n",
        "\n",
        "      image = cv2.imread(file_path, -1)\n",
        "      image = cv2.cvtColor(cv2.flip(image, 1), cv2.COLOR_BGR2RGB)    \n",
        "      \n",
        "      image.flags.writeable = False\n",
        "\n",
        "      # make detection\n",
        "      results = pose.process(image)\n",
        "\n",
        "      \n",
        "      if results.pose_landmarks:\n",
        "        for idx,pose_result in enumerate(results.pose_landmarks.landmark):\n",
        "          # 11-32 is the nodes of body except the face\n",
        "          if( idx >=11 and idx<=32):\n",
        "            text = text + str(pose_result.x) + \" \" + str(pose_result.y) + \" \"\n",
        "\n",
        "      # ct +=1\n",
        "      # if ct ==10:\n",
        "      data[\"labels\"].append(filename)\n",
        "      data[\"feature\"].append(text)\n",
        "\n",
        "\n",
        "\n",
        "df = pd.DataFrame(data, columns = [\"labels\",\"feature\"])\n",
        "df.to_csv('/content/data.csv', index=False)"
      ],
      "metadata": {
        "id": "fDPX5PQeV8Hd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resnet for skeleton image input"
      ],
      "metadata": {
        "id": "2l4ILNboe67X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        " \n",
        "class Block(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, downsample):\n",
        "        super().__init__()\n",
        "        if downsample:\n",
        "            self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=(1, 1), stride=(2, 2), bias=False),\n",
        "                nn.BatchNorm2d(out_channels,eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "            )\n",
        "        else:\n",
        "            self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
        "            self.shortcut = nn.Sequential()\n",
        "\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels,eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "            \n",
        "    def forward(self, input):\n",
        "        shortcut = self.shortcut(input)\n",
        "        input = nn.ReLU()(self.bn1(self.conv1(input)))\n",
        "        input = nn.ReLU()(self.bn2(self.conv2(input)))\n",
        "        input = input + shortcut\n",
        "        return nn.ReLU()(input)\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, resblock, outputs=10):\n",
        "        super().__init__()\n",
        "        self.layer0 = nn.Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
        "        self.layer1 = nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.layer2 = nn.ReLU(inplace=True)\n",
        "        self.layer3 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
        "        self.layer4 = nn.Sequential(resblock(64, 64, downsample=False))\n",
        "        self.layer5 = nn.Sequential(resblock(64, 128, downsample=True))\n",
        "        self.layer6 = nn.Sequential(resblock(128, 256, downsample=True))\n",
        "        self.layer7 = nn.Sequential(resblock(256, 512, downsample=True))\n",
        "\n",
        "        self.fc = nn.Linear(65536, outputs)\n",
        "\n",
        "    def forward(self, input):\n",
        "        input = self.layer0(input)\n",
        "        input = self.layer1(input)\n",
        "        input = self.layer2(input)\n",
        "        input = self.layer3(input)\n",
        "        input = self.layer4(input)\n",
        "        input = self.layer5(input)\n",
        "        input = self.layer6(input)\n",
        "        input = self.layer7(input)\n",
        "        input = torch.flatten(input, start_dim=1)\n",
        "        input = self.fc(input)\n",
        "        probs = F.softmax(input, dim=1)\n",
        "\n",
        "\n",
        "        return input,probs"
      ],
      "metadata": {
        "id": "VhROeIfze5zA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class ImageFlowDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, root_dir, transform):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.class_names = os.listdir(root_dir)\n",
        "        self.classes = sorted(self.class_names)\n",
        "        self.class_to_idx = {name: i for i, name in enumerate(self.class_names)}\n",
        "        self.image_filenames = []\n",
        "        self.labels = []\n",
        "        for class_name in self.class_names:\n",
        "            class_dir = os.path.join(root_dir, class_name)\n",
        "            for i, image_name in enumerate(os.listdir(class_dir)):\n",
        "                image_path = os.path.join(class_dir, image_name)\n",
        "                self.image_filenames.append(image_path)\n",
        "                self.labels.append(self.class_to_idx[class_name])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_filenames)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        images = []\n",
        "        for i in range(10):\n",
        "            image_idx = idx+i\n",
        "            if image_idx < len(self.image_filenames):\n",
        "                image_path = self.image_filenames[image_idx]\n",
        "                image = cv2.imread(image_path)\n",
        "                images.append(image)\n", 
        "            else:\n",
        "                # if index is out of range, return an empty image\n",
        "                empty_image = np.zeros((100, 100, 3), dtype=np.uint8)\n",
        "                images.append(empty_image)\n",
        "        image_flow = np.hstack(images)\n",
        "        image_flow = self.transform(image_flow)\n",
        "        label = self.labels[idx]\n",
        "        return image_flow, torch.tensor(label)\n",
        "\n",
        "# Data augmentation\n",
        "data_transforms =transforms.Compose([\n",
        "                  transforms.ToTensor(),\n",
        "                  transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "                  transforms.RandomApply([transforms.Lambda(lambda x: x + torch.randn_like(x)*0.1)], p=0.5)\n",
        "        ])\n",
        "\n",
        "data_dir = '/content/drive/MyDrive/4010/skeleton_image'\n",
        "\n",
        "res_dataset = ImageFlowDataset(root_dir=data_dir, transform=data_transforms)\n",
        "\n",
        "res_train_length = int(len(res_dataset)*0.8)\n",
        "res_test_length = int(len(res_dataset))-res_train_length\n",
        "\n",
        "res_train_dataset,res_test_dataset=torch.utils.data.random_split(res_dataset,[res_train_length,res_test_length])\n",
        "\n",
        "res_train_loader = DataLoader(res_train_dataset, batch_size=16, shuffle=False, drop_last=True)\n",
        "res_test_loader = DataLoader(res_test_dataset, batch_size=16, shuffle=False, drop_last=True)\n",
        "class_names = res_dataset.classes\n",
        "print(class_names)\n",
        "if torch.cuda.is_available(): \n",
        "     device = \"cuda\" \n",
        "     print(\"using cuda\")\n",
        "else: \n",
        "     device = \"cpu\""
      ],
      "metadata": {
        "id": "fMoRfALyeSrE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, criterion,optimizer,train_loader, num_epochs=10):\n",
        "    model.train() \n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        # Forward\n",
        "        outputs, probs = model(inputs)\n",
        "        _, preds = torch.max(probs, 1)\n",
        "        loss = criterion(outputs, labels)\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        # Backward\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total += labels.size(0)\n",
        "        correct += (preds == labels).sum().item()           \n",
        "\n",
        "    epoch_acc = correct / total\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "    print(f'Training Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "    print()      \n",
        "    return model, optimizer, epoch_loss"
      ],
      "metadata": {
        "id": "bslfmd6Yh1LV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def val_model(model, criterion, optimizer, test_loader, num_epochs=10):\n",
        "    model.eval() \n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    y_pred=[]\n",
        "    y_true=[]\n",
        "    for inputs, labels in test_loader:   \n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        # Forward\n",
        "        outputs,probs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        _, preds = torch.max(probs, 1)\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        total += labels.size(0)\n",
        "        correct += (preds == labels).sum().item()\n",
        "\n",
        "        pred = outputs.data.argmax(1).cpu().numpy()\n",
        "        y_pred.extend(pred)\n",
        "        true = labels.data.cpu().numpy()\n",
        "        y_true.extend(true)\n",
        "\n",
        "    epoch_acc = correct / total\n",
        "    epoch_loss = running_loss / len(test_loader.dataset)\n",
        "    print(f'Testing Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "    print()      \n",
        "    return model, epoch_loss, epoch_acc, y_pred, y_true"
      ],
      "metadata": {
        "id": "bhq1ElXkh5Ay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def training_loop(model, criterion, optimizer, epochs, train_dataloader, test_dataloader):\n",
        "  best_model_wts = copy.deepcopy(model.state_dict())\n",
        "  best_acc = 0.0\n",
        "  # set objects for storing metrics\n",
        "  train_loss = []\n",
        "  val_loss = []\n",
        "  y_trues=[]\n",
        "  y_preds=[]\n",
        "  # Train model\n",
        "  for epoch in range(0, epochs):\n",
        "    print(f'Epoch: {epoch+1}\\t')\n",
        "    # training\n",
        "    model, optimizer, t_loss = train_model(model, criterion, optimizer, train_dataloader,num_epochs=epochs)\n",
        "    train_loss.append(train_loss)\n",
        "\n",
        "    # # validation\n",
        "    with torch.no_grad():\n",
        "      model, v_loss, acc, y_pred, y_true = val_model(model, criterion, optimizer, test_dataloader,num_epochs=epochs)\n",
        "      val_loss.append(v_loss)\n",
        "      y_trues.extend(y_true)\n",
        "      y_preds.extend(y_pred)\n",
        "    if acc > best_acc:\n",
        "      best_acc = acc\n",
        "      best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "  print(f'Best val Acc: {best_acc:4f}')\n",
        "  model.load_state_dict(best_model_wts)\n",
        "\n",
        "  cf_matrix = confusion_matrix(y_true, y_pred)\n",
        "  # Create pandas dataframe\n",
        "  dataframe = pd.DataFrame(cf_matrix, index=class_names, columns=class_names)\n",
        "  sns.heatmap(dataframe, annot=True, cbar=None,cmap=\"YlGnBu\",fmt=\"d\")\n",
        "  plt.title(\"Confusion Matrix\"), plt.tight_layout()\n",
        "  plt.ylabel(\"True Class\"), \n",
        "  plt.xlabel(\"Predicted Class\")\n",
        "  plt.show()\n",
        "\n",
        "  return train_loss,val_loss"
      ],
      "metadata": {
        "id": "1-APDRBrh6aS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':            \n",
        "  model = ResNet(Block).to(device)\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  t_loss, v_loss = training_loop(model, criterion, optimizer,100, res_train_loader, res_test_loader) "
      ],
      "metadata": {
        "id": "c85c59jfh8Px"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using CNN for accelerometer data"
      ],
      "metadata": {
        "id": "3jzer0b7t0fn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ChannelAttention(nn.Module):\n",
        "    def __init__(self, in_planes, ratio=16):\n",
        "        super(ChannelAttention, self).__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool1d(1)\n",
        "        self.max_pool = nn.AdaptiveMaxPool1d(1)\n",
        "        self.fc1   = nn.Conv1d(in_planes, in_planes // ratio, 1, bias=False)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.fc2   = nn.Conv1d(in_planes // ratio, in_planes, 1, bias=False)  \n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        avg_out = self.fc2(self.relu1(self.fc1(self.avg_pool(x))))\n",
        "        max_out = self.fc2(self.relu1(self.fc1(self.max_pool(x))))\n",
        "        out = avg_out + max_out\n",
        "        out = self.sigmoid(out)\n",
        "        return out\n",
        "\n",
        "class SpatialAttention(nn.Module):\n",
        "    def __init__(self, kernel_size=7):\n",
        "        super(SpatialAttention, self).__init__()\n",
        "        \n",
        "        assert kernel_size in (3, 7), 'kernel size must be 3 or 7'\n",
        "        padding = 3 if kernel_size == 7 else 1\n",
        "        \n",
        "        self.conv1 = nn.Conv1d(2, 1, kernel_size, padding=padding, bias=False)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
        "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
        "        x = torch.cat([avg_out, max_out], dim=1)\n",
        "        x = self.conv1(x)\n",
        "        x = self.sigmoid(x)\n",
        "        return x\n",
        "\n",
        "class CBAMBlock(nn.Module):\n",
        "    def __init__(self, in_planes, ratio=16, kernel_size=7):\n",
        "        super(CBAMBlock, self).__init__()\n",
        "        self.ca = ChannelAttention(in_planes, ratio)\n",
        "        self.sa = SpatialAttention(kernel_size)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = x * self.ca(x)\n",
        "        out = out * self.sa(out)\n",
        "        return out\n",
        "\n",
        "class CBAMModel(nn.Module):\n",
        "    def __init__(self,outputs=8):\n",
        "        super(CBAMModel,self).__init__()\n",
        "        \n",
        "        self.conv1 = nn.Conv1d(in_channels=14, out_channels=64, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm1d(64)\n",
        "        self.cbam1 = CBAMBlock(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.pool1 = nn.MaxPool1d(2)\n",
        "        \n",
        "        self.conv2 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm1d(128)\n",
        "        self.cbam2 = CBAMBlock(128)\n",
        "        self.pool2 = nn.MaxPool1d(2)\n",
        "        self.f = nn.Flatten()\n",
        "        self.fc = nn.Linear(128, 64)\n",
        "        self.output= nn.Linear(64,outputs)\n",
        "\n",
        "    def forward(self, input):\n",
        "        input = self.conv1(input)\n",
        "        input = self.bn1(input)\n",
        "        input = self.relu(input)\n",
        "        input = self.cbam1(input)\n",
        "        input = self.pool1(input)\n",
        "\n",
        "        input = self.conv2(input)\n",
        "        input = self.bn2(input)\n",
        "        input = self.relu(input)\n",
        "        input = self.cbam2(input)\n",
        "\n",
        "        input = self.f(input)\n",
        "        input = self.fc(input)\n",
        "        input = self.output(input)\n",
        "        probs = F.softmax(input, dim=1)\n",
        "\n",
        "        return input,probs"
      ],
      "metadata": {
        "id": "cp2ylmkXAKQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "class AccelDataset(Dataset):\n",
        "    def __init__(self, root_dir):\n",
        "        self.root_dir = root_dir\n",
        "        self.classes = os.listdir(root_dir)\n",
        "\n",
        "    def __len__(self):\n",
        "        total_data = 0\n",
        "        for c in self.classes:\n",
        "            data_dir = os.path.join(self.root_dir, c)\n",
        "            total_data += len(os.listdir(data_dir))\n",
        "        return total_data\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        class_idx = 0\n",
        "        while True:\n",
        "            data_dir = os.path.join(self.root_dir, self.classes[class_idx])\n",
        "            num_data = len(os.listdir(data_dir))\n",
        "            if idx < num_data:\n",
        "                break\n",
        "            else:\n",
        "                idx -= num_data\n",
        "                class_idx += 1\n",
        "        file_path = os.path.join(data_dir, os.listdir(data_dir)[idx])\n",
        "\n",
        "        data = np.loadtxt(file_path)[:, :-1] # remove the last column\n",
        "        \n",
        "        # Padding to ensure that all data has the same length\n",
        "        max_length = 14\n",
        "        current_length = data.shape[0]\n",
        "        if current_length < max_length:\n",
        "            padding = np.zeros((max_length-current_length, 18))\n",
        "            data = np.concatenate((data, padding), axis=0)\n",
        "        elif current_length > max_length:\n",
        "            data = data[:max_length, :]\n",
        "\n",
        "        label = class_idx\n",
        "        return torch.tensor(data).float(), torch.tensor(label)\n",
        "\n",
        "\n",
        "data_dir = '/content/drive/MyDrive/4010/accel'\n",
        "\n",
        "CBAM_dataset = AccelDataset(root_dir=data_dir)\n",
        "\n",
        "CBAM_train_length = int(len(CBAM_dataset)*0.8)\n",
        "CBAM_test_length = int(len(CBAM_dataset))-CBAM_train_length\n",
        "\n",
        "CBAM_train_dataset,CBAM_test_dataset=torch.utils.data.random_split(CBAM_dataset,[CBAM_train_length,CBAM_test_length])\n",
        "\n",
        "CBAM_train_loader = DataLoader(CBAM_train_dataset, batch_size=16, shuffle=False, drop_last=True)\n",
        "CBAM_test_loader = DataLoader(CBAM_test_dataset, batch_size=16, shuffle=False, drop_last=True)\n",
        "class_names = CBAM_dataset.classes\n",
        "print(class_names)\n",
        "if torch.cuda.is_available(): \n",
        "     device = \"cuda\" \n",
        "     print(\"using cuda\")\n",
        "else: \n",
        "     device = \"cpu\""
      ],
      "metadata": {
        "id": "rx6JiMvBybon"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':            \n",
        "  model = CBAMModel(outputs=8).to(device)\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  t_loss, v_loss = training_loop(model, criterion, optimizer,100, CBAM_train_loader, CBAM_train_loader) "
      ],
      "metadata": {
        "id": "D-6vLhHKFnX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        " \n",
        "plt.title(\"Validation loss of model\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.plot(v_loss, label='Validation Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "j-qkNYvQYRHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using BILSTM for coordinate data"
      ],
      "metadata": {
        "id": "Go_BbtvCNYtn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BiLSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
        "        super(BiLSTM, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, bidirectional=True, num_layers=num_layers)\n",
        "        self.fc = nn.Linear(1024, num_classes)\n",
        "        self.f = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(440, input_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Set initial hidden and cell states\n",
        "        h0 = torch.zeros(2 * 2, x.size(0), 512).to(device)\n",
        "        c0 = torch.zeros(2 * 2, x.size(0), 512).to(device)\n",
        "        \n",
        "        x = self.f(x)\n",
        "        x = self.fc1(x)\n",
        "        # Forward propagate LSTM\n",
        "        out, _ = self.lstm(x)\n",
        "        \n",
        "        \n",
        "        # Decode the hidden state of the last time step\n",
        "        out = self.fc(out)\n",
        "        probs = F.softmax(out, dim=1)\n",
        "\n",
        "        \n",
        "        return out,probs"
      ],
      "metadata": {
        "id": "r_s96pcPe6_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_map = {'A1': 0, 'A2': 1, 'A3': 2, 'A4': 3, 'A5': 4, 'A6': 5, 'A7': 6, 'A8': 7}\n",
        "\n",
        "class CoordinateDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, csv_path):\n",
        "        self.data = pd.read_csv(csv_path,skiprows=1)\n",
        "        self.classes = ['A1', 'A2', 'A3', 'A4', 'A5', 'A6', 'A7', 'A8']\n",
        "        self.data.fillna('0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0', inplace=True)  # replace missing values with 0\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Select 10 consecutive rows from the CSV file\n",
        "        rows = self.data.iloc[idx:idx+10]\n",
        "        # Merge the 10 rows into a single input vector\n",
        "        features = []\n",
        "        for feature in rows.iloc[:, 1]:\n",
        "          tmp = np.fromstring(feature, dtype=float, sep=' ')\n",
        "          features.append(tmp)\n",
        "        \n",
        "        features = np.array(features)\n",
        "        input_vector = torch.from_numpy(features)\n",
        "        input_vector = input_vector.to(torch.float32)\n",
        "        # Extract the label from the first row and convert it to an integer\n",
        "        label = label_map[str(rows.iloc[0, 0])]\n",
        "        return input_vector, torch.tensor(label)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data) - 9\n",
        "\n",
        "  \n",
        "# Data augmentation\n",
        "csv_dir = '/content/data.csv'\n",
        "\n",
        "BiLSTM_dataset = CoordinateDataset(csv_path = csv_dir)\n",
        "\n",
        "BiLSTM_train_length = int(len(BiLSTM_dataset)*0.8)\n",
        "BiLSTM_test_length = int(len(BiLSTM_dataset))-BiLSTM_train_length\n",
        "\n",
        "BiLSTM_train_dataset,BiLSTM_test_dataset=torch.utils.data.random_split(BiLSTM_dataset,[BiLSTM_train_length,BiLSTM_test_length])\n",
        "\n",
        "BiLSTM_train_loader = DataLoader(BiLSTM_train_dataset, batch_size=16, shuffle=False, drop_last=True)\n",
        "BiLSTM_test_loader = DataLoader(BiLSTM_test_dataset, batch_size=16, shuffle=False, drop_last=True)\n",
        "class_names = BiLSTM_dataset.classes\n",
        "print(class_names)\n",
        "if torch.cuda.is_available(): \n",
        "     device = \"cuda\" \n",
        "     print(\"using cuda\")\n",
        "else: \n",
        "     device = \"cpu\""
      ],
      "metadata": {
        "id": "9gxI5CONIj0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':            \n",
        "  model = BiLSTM(input_size=75,hidden_size=512,num_layers=2,num_classes=8).to(device)\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  t_loss, v_loss = training_loop(model, criterion, optimizer,100,BiLSTM_train_loader,BiLSTM_test_loader) "
      ],
      "metadata": {
        "id": "AN_IMolJdPir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fusion Model"
      ],
      "metadata": {
        "id": "-LZVkpF_lOto"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Fusion_Three(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Fusion_Three, self).__init__()\n",
        "        self.BILSTM = BiLSTM(input_size=75,hidden_size=512,num_layers=2,num_classes=12800)\n",
        "        self.resnet = ResNet(Block,outputs = 512)\n",
        "        self.CBAM = CBAMModel(outputs=256)      \n",
        "        self.drop = nn.Dropout()\n",
        "        self.fc1 = nn.Linear(13568, 768)\n",
        "        self.fc2 = nn.Linear(768,512)\n",
        "        self.fc_out = nn.Linear(512, 8)\n",
        "        \n",
        "    def forward(self, x1, x2, x3):\n",
        "        \n",
        "        x1,_ = self.BILSTM(x1)\n",
        "        x1 = x1.view(x1.size(0), -1)\n",
        "        \n",
        "        x2,_ = self.resnet(x2)\n",
        "        x2 = x2.view(x2.size(0), -1)\n",
        "        \n",
        "        x3,_ = self.CBAM(x3)\n",
        "        x3 = x3.view(x3.size(0), -1)\n",
        "\n",
        "        # Concatenate in dim1 (feature dimension)\n",
        "        x = torch.cat((x1, x2, x3), 1)\n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.fc_out(x)\n",
        "        probs = F.softmax(x, dim=1)\n",
        "\n",
        "        return x,probs\n",
        "\n",
        "\n",
        "class Fusion_Two(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Fusion_Two, self).__init__()\n",
        "        self.resnet = ResNet(Block,outputs = 512)\n",
        "        self.CBAM = CBAMModel(outputs=256)      \n",
        "        self.fc1 = nn.Linear(768, 768)\n",
        "        self.fc2 = nn.Linear(768,512)\n",
        "        self.fc_out = nn.Linear(512, 8)\n",
        "        \n",
        "    def forward(self, x1, x2):\n",
        "        \n",
        "        x1,_ = self.CBAM(x1)\n",
        "        x1 = x1.view(x1.size(0), -1)\n",
        "        \n",
        "        x2,_ = self.resnet(x2)\n",
        "        x2 = x2.view(x2.size(0), -1)\n",
        "\n",
        "        # Concatenate in dim1 (feature dimension)\n",
        "        x = torch.cat((x1, x2), 1)\n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.fc_out(x)\n",
        "        probs = F.softmax(x, dim=1)\n",
        "\n",
        "        return x,probs"
      ],
      "metadata": {
        "id": "qT6qQRW3lSSp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_fusion_model_3(model, criterion,optimizer,num_epochs=10):\n",
        "    model.train() \n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch_BiLSTM, batch_res, batch_CBAM in zip(BiLSTM_train_loader,res_train_loader, CBAM_train_loader):\n",
        "        inputs_BiLSTM, labels = batch_BiLSTM\n",
        "        inputs_res, labels = batch_res\n",
        "        inputs_CBAM, labels = batch_CBAM\n",
        "\n",
        "        inputs_BiLSTM = inputs_BiLSTM.to(device)\n",
        "        inputs_res = inputs_res.to(device)\n",
        "        inputs_CBAM = inputs_CBAM.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        # Forward\n",
        "        outputs, probs = model(inputs_BiLSTM,inputs_res,inputs_CBAM)\n",
        "        _, preds = torch.max(probs, 1)\n",
        "        loss = criterion(outputs, labels)\n",
        "        running_loss += loss.item() * (inputs_BiLSTM.size(0)+inputs_CBAM.size(0)+inputs_res.size(0))\n",
        "        # Backward\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total += labels.size(0)\n",
        "        correct += (preds == labels).sum().item()\n",
        "    epoch_acc = correct / total\n",
        "    epoch_loss = running_loss / (len(BiLSTM_train_loader.dataset)+len(CBAM_train_loader.dataset)+len(res_train_loader.dataset))\n",
        "    print(f'Training Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "    print()      \n",
        "    return model, optimizer, epoch_loss"
      ],
      "metadata": {
        "id": "Ag30zZ28oUtU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_fusion_model_2(model, criterion,optimizer,num_epochs=10):\n",
        "    model.train() \n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch_res, batch_CBAM in zip(res_train_loader, CBAM_train_loader):\n",
        "        inputs_res, labels = batch_res\n",
        "        inputs_CBAM, labels = batch_CBAM\n",
        "\n",
        "        inputs_res = inputs_res.to(device)\n",
        "        inputs_CBAM = inputs_CBAM.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        # Forward\n",
        "        outputs, probs = model(inputs_CBAM,inputs_res)\n",
        "        _, preds = torch.max(probs, 1)\n",
        "        loss = criterion(outputs, labels)\n",
        "        running_loss += loss.item() * (inputs_CBAM.size(0)+inputs_res.size(0))\n",
        "        # Backward\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total += labels.size(0)\n",
        "        correct += (preds == labels).sum().item()\n",
        "    epoch_acc = correct / total\n",
        "    epoch_loss = running_loss / (len(CBAM_train_loader.dataset)+len(res_train_loader.dataset))\n",
        "    print(f'Training Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "    print()      \n",
        "    return model, optimizer, epoch_loss"
      ],
      "metadata": {
        "id": "BgmHd7Jgu_vc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def val_fusion_model_3(model, criterion, optimizer, num_epochs=10):\n",
        "    model.eval() \n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    y_true=[]\n",
        "    y_pred=[]\n",
        "    dataloaders= zip(BiLSTM_train_loader,res_train_loader, CBAM_train_loader)\n",
        "    for batch_BiLSTM, batch_res, batch_CBAM in dataloaders:\n",
        "        inputs_BiLSTM, labels = batch_BiLSTM\n",
        "        inputs_res, labels = batch_res\n",
        "        inputs_CBAM, labels = batch_CBAM\n",
        "\n",
        "        inputs_BiLSTM = inputs_BiLSTM.to(device)\n",
        "        inputs_res = inputs_res.to(device)\n",
        "        inputs_CBAM = inputs_CBAM.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        # Forward\n",
        "        outputs,probs = model(inputs_BiLSTM,inputs_res,inputs_CBAM)\n",
        "        loss = criterion(outputs, labels)\n",
        "        _, preds = torch.max(probs, 1)\n",
        "\n",
        "        running_loss += loss.item() * (inputs_BiLSTM.size(0)+inputs_CBAM.size(0)+inputs_res.size(0))\n",
        "        total += labels.size(0)\n",
        "        correct += (preds == labels).sum().item()\n",
        "\n",
        "        pred = outputs.data.argmax(1).cpu().numpy()\n",
        "        y_pred.extend(pred)\n",
        "        true = labels.data.cpu().numpy()\n",
        "        y_true.extend(true)\n",
        "\n",
        "    epoch_acc = correct / total\n",
        "    epoch_loss = running_loss / (len(BiLSTM_train_loader.dataset)+len(CBAM_train_loader.dataset)+len(res_train_loader.dataset))\n",
        "    print(f'Testing Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "    print()      \n",
        "    return model, epoch_loss, epoch_acc"
      ],
      "metadata": {
        "id": "MVJxfmxP0okx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def val_fusion_model_2(model, criterion, optimizer, num_epochs=10):\n",
        "    model.eval() \n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    y_true=[]\n",
        "    y_pred=[]\n",
        "    dataloaders= zip(res_train_loader, CBAM_train_loader)\n",
        "    for batch_res, batch_CBAM in dataloaders:\n",
        "        inputs_res, labels = batch_res\n",
        "        inputs_CBAM, labels = batch_CBAM\n",
        "\n",
        "        inputs_res = inputs_res.to(device)\n",
        "        inputs_CBAM = inputs_CBAM.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        # Forward\n",
        "        outputs,probs = model(inputs_CBAM,inputs_res)\n",
        "        loss = criterion(outputs, labels)\n",
        "        _, preds = torch.max(probs, 1)\n",
        "\n",
        "        running_loss += loss.item() * (inputs_CBAM.size(0)+inputs_res.size(0))\n",
        "        total += labels.size(0)\n",
        "        correct += (preds == labels).sum().item()\n",
        "\n",
        "        pred = outputs.data.argmax(1).cpu().numpy()\n",
        "        y_pred.extend(pred)\n",
        "        true = labels.data.cpu().numpy()\n",
        "        y_true.extend(true)\n",
        "\n",
        "    epoch_acc = correct / total\n",
        "    epoch_loss = running_loss / (len(CBAM_train_loader.dataset)+len(res_train_loader.dataset))\n",
        "    print(f'Testing Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "    print()      \n",
        "    return model, epoch_loss, epoch_acc, y_true, y_pred"
      ],
      "metadata": {
        "id": "jaMCoKjOvjGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def training_fusion_loop_3(model, criterion, optimizer, epochs):\n",
        "  best_model_wts = copy.deepcopy(model.state_dict())\n",
        "  best_acc = 0.0\n",
        "  # set objects for storing metrics\n",
        "  train_loss = []\n",
        "  val_loss = []\n",
        "  y_trues=[]\n",
        "  y_preds=[]\n",
        "  # Train model\n",
        "  for epoch in range(0, epochs):\n",
        "    print(f'Epoch: {epoch+1}\\t')\n",
        "    # training\n",
        "    model, optimizer, t_loss = train_fusion_model_3(model, criterion, optimizer, num_epochs=epochs)\n",
        "    train_loss.append(train_loss)\n",
        "\n",
        "    # # validation\n",
        "    with torch.no_grad():\n",
        "      model, v_loss, acc, y_true, y_pred = val_fusion_model_3(model, criterion, optimizer,  num_epochs=epochs)\n",
        "      val_loss.append(v_loss)\n",
        "      y_trues.extend(y_true)\n",
        "      y_preds.extend(y_pred)\n",
        "\n",
        "    if acc > best_acc:\n",
        "      best_acc = acc\n",
        "      best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "  print(f'Best val Acc: {best_acc:4f}')\n",
        "  model.load_state_dict(best_model_wts)\n",
        "\n",
        "  cf_matrix = confusion_matrix(y_true, y_pred)\n",
        "  # Create pandas dataframe\n",
        "  dataframe = pd.DataFrame(cf_matrix, index=class_names, columns=class_names)\n",
        "  sns.heatmap(dataframe, annot=True, cbar=None,cmap=\"YlGnBu\",fmt=\"d\")\n",
        "  plt.title(\"Confusion Matrix\"), plt.tight_layout()\n",
        "  plt.ylabel(\"True Class\"), \n",
        "  plt.xlabel(\"Predicted Class\")\n",
        "  plt.show()\n",
        "  return train_loss,val_loss"
      ],
      "metadata": {
        "id": "nrtlpLHi12le"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def training_fusion_loop_2(model, criterion, optimizer, epochs):\n",
        "  best_model_wts = copy.deepcopy(model.state_dict())\n",
        "  best_acc = 0.0\n",
        "  # set objects for storing metrics\n",
        "  train_loss = []\n",
        "  val_loss = []\n",
        "  y_trues=[]\n",
        "  y_preds=[]\n",
        "  # Train model\n",
        "  for epoch in range(0, epochs):\n",
        "    print(f'Epoch: {epoch+1}\\t')\n",
        "    # training\n",
        "    model, optimizer, t_loss = train_fusion_model_2(model, criterion, optimizer, num_epochs=epochs)\n",
        "    train_loss.append(train_loss)\n",
        "\n",
        "    # # validation\n",
        "    with torch.no_grad():\n",
        "      model, v_loss, acc, y_true, y_pred = val_fusion_model_2(model, criterion, optimizer,  num_epochs=epochs)\n",
        "      val_loss.append(v_loss)\n",
        "      y_trues.extend(y_true)\n",
        "      y_preds.extend(y_pred)\n",
        "\n",
        "    if acc > best_acc:\n",
        "      best_acc = acc\n",
        "      best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "  print(f'Best val Acc: {best_acc:4f}')\n",
        "  model.load_state_dict(best_model_wts)\n",
        "\n",
        "  cf_matrix = confusion_matrix(y_true, y_pred)\n",
        "  # Create pandas dataframe\n",
        "  dataframe = pd.DataFrame(cf_matrix, index=class_names, columns=class_names)\n",
        "  sns.heatmap(dataframe, annot=True, cbar=None,cmap=\"YlGnBu\",fmt=\"d\")\n",
        "  plt.title(\"Confusion Matrix\"), plt.tight_layout()\n",
        "  plt.ylabel(\"True Class\"), \n",
        "  plt.xlabel(\"Predicted Class\")\n",
        "  plt.show()\n",
        "  return train_loss,val_loss"
      ],
      "metadata": {
        "id": "DDWFXj3bwIsg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()\n",
        "import gc\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "Ga7natIjBH2-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':            \n",
        "  model = Fusion_Two().to(device)\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  t_loss, v_loss = training_fusion_loop_2(model, criterion, optimizer,100) "
      ],
      "metadata": {
        "id": "eFuEvQ9xwMNu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':            \n",
        "  model = Fusion_Three().to(device)\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  t_loss, v_loss = training_fusion_loop_3(model, criterion, optimizer,100) "
      ],
      "metadata": {
        "id": "oo2mE7GV1_PT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
